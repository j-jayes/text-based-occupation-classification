{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first thing we have to do is collect some schemas that classify occupations.\n",
    "\n",
    "We will begin with the SSYK schema from Statistics Sweden.\n",
    "\n",
    "The document is available at https://www.scb.se/contentassets/c9d055b6f2114b62bd23c33602b56da5/ov9999_2012a01_br_x70br1201.pdf\n",
    "\n",
    "It is stored in data/pdf/ssyk.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Define the path to your PDF document\n",
    "pdf_path = '../data/pdf/ssyk.pdf'\n",
    "\n",
    "# Define the start and end pages for your document\n",
    "start_page = 33  # replace with your actual start page\n",
    "end_page = 35  # replace with your actual end page\n",
    "\n",
    "# Define the regex pattern for occupation extraction\n",
    "pattern = re.compile(\n",
    "    r'^(?P<code>\\d{1,4})\\s(?P<title>[^\\n]+)\\n(?P<description>(?:.(?!\\n\\d{1,4}\\s))*.)',\n",
    "    re.MULTILINE | re.DOTALL\n",
    ")\n",
    "level_3_pattern = re.compile(\n",
    "    r'Yrkesgrupp (\\d{3})\\s*(.*?)\\n(.*?)(?=\\nYrkesgrupp \\d{3}|\\n\\d{4}|\\Z)',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "# Define the path to save the JSON files\n",
    "json_path = '../data/schemas/ssyk/'\n",
    "\n",
    "# Function to process a single page\n",
    "def process_page(page):\n",
    "    page_text = page.get_text()\n",
    "    page_matches = pattern.findall(page_text)\n",
    "    level_3_matches = level_3_pattern.findall(page_text)\n",
    "    occupations = []\n",
    "    for match in page_matches + level_3_matches:\n",
    "        code, title, description = match\n",
    "        level = len(code)\n",
    "        occupation = {\n",
    "            \"code\": code.strip(),\n",
    "            \"title\": title.strip(),\n",
    "            \"description\": description.strip(),\n",
    "            \"level\": level\n",
    "        }\n",
    "        occupations.append(occupation)\n",
    "    return occupations\n",
    "\n",
    "# Function to process the entire document and save each page's data to a separate JSON file\n",
    "def process_document(pdf_path, start_page, end_page, json_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    all_occupations = []\n",
    "    for page_num in range(start_page - 1, end_page):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        page_occupations = process_page(page)\n",
    "        all_occupations.extend(page_occupations)\n",
    "        # Save the current page occupations to a JSON file\n",
    "        with open(os.path.join(json_path, f'occupations_page_{page_num+1}.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(page_occupations, f, ensure_ascii=False, indent=4)\n",
    "    pdf_document.close()\n",
    "    # Save all occupations to a single JSON file\n",
    "    with open(os.path.join(json_path, 'combined_occupations.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_occupations, f, ensure_ascii=False, indent=4)\n",
    "    return all_occupations\n",
    "\n",
    "# Process the document and save each page's data to a separate JSON file\n",
    "all_occupations = process_document(pdf_path, start_page, end_page, json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, start_page, end_page):\n",
    "    # Open the PDF file\n",
    "    with fitz.open(pdf_path) as pdf_document:\n",
    "        text = \"\"\n",
    "        for page_num in range(start_page - 1, end_page):\n",
    "            # Page numbers in the PDF are 0-indexed\n",
    "            page = pdf_document.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def clean_and_join_lines(text_lines):\n",
    "    text = '\\n'.join(text_lines)\n",
    "    text = re.sub(r'-\\s*\\n\\s*', '', text)\n",
    "    text = re.sub(r'\\n(?=\\d{1,4}\\s)', '##SPLIT##', text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return text.split('##SPLIT##')\n",
    "\n",
    "def is_likely_occupation_line(line):\n",
    "    return re.match(r'^\\d{1,4}\\s+\\D', line) and not 'fotnot' in line.lower()\n",
    "\n",
    "def parse_cleaned_text_to_json(text_lines):\n",
    "    occupations = []\n",
    "    pattern = re.compile(r'^(\\d{1,4})\\s+(.+?)(?:\\s+(niv√•\\s\\d))?\\s*$', re.MULTILINE)\n",
    "    \n",
    "    for line in text_lines:\n",
    "        match = pattern.match(line)\n",
    "        if match:\n",
    "            code, title, level_suffix = match.groups()\n",
    "            level = len(code)\n",
    "            if level_suffix:\n",
    "                title += f' {level_suffix}'\n",
    "            title = title.strip()\n",
    "            occupations.append({\n",
    "                \"code\": code,\n",
    "                \"title\": title,\n",
    "                \"level\": level\n",
    "            })\n",
    "    \n",
    "    return occupations\n",
    "\n",
    "def save_to_json(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Define the path to the PDF file and the pages to extract\n",
    "pdf_path = '../data/pdf/ssyk.pdf'\n",
    "start_page = 23\n",
    "end_page = 32\n",
    "\n",
    "# Extract and process text from PDF\n",
    "extracted_text = extract_text_from_pdf(pdf_path, start_page, end_page)\n",
    "cleaned_lines = clean_and_join_lines(extracted_text)\n",
    "filtered_lines = [line for line in cleaned_lines if is_likely_occupation_line(line)]\n",
    "occupations_json = parse_cleaned_text_to_json(filtered_lines)\n",
    "\n",
    "# Save the occupations data to a JSON file\n",
    "json_file_path = 'ssyk_schema_codes_titles_levels.json'\n",
    "save_to_json(occupations_json, json_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
